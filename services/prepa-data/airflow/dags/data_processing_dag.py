"""
DAG Airflow pour le traitement quotidien des donnÃ©es PrepaData
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
import requests
import os

default_args = {
    'owner': 'edupath',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'prepa_data_processing',
    default_args=default_args,
    description='Traitement quotidien des donnÃ©es Ã©tudiants',
    schedule_interval=timedelta(hours=6),  # Toutes les 6 heures
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['edupath', 'data-processing'],
)

def sync_lms_data():
    """Synchronise les donnÃ©es depuis LMSConnector"""
    lms_url = os.getenv('LMS_CONNECTOR_URL', 'http://lms-connector:3001')
    try:
        response = requests.get(f'{lms_url}/sync', timeout=30)
        response.raise_for_status()
        print(f"âœ… LMS data synced: {response.json()}")
        return response.json()
    except Exception as e:
        print(f"âŒ Error syncing LMS data: {e}")
        raise

def process_student_features():
    """Traite les features pour tous les Ã©tudiants"""
    prepa_url = os.getenv('PREPA_DATA_URL', 'http://prepa-data:3002')
    # Dans un vrai scÃ©nario, on rÃ©cupÃ©rerait la liste des Ã©tudiants depuis la DB
    student_ids = [1, 2, 3, 4, 5]  # Exemple
    
    processed = 0
    for student_id in student_ids:
        try:
            response = requests.get(f'{prepa_url}/features/{student_id}', timeout=10)
            if response.status_code == 200:
                processed += 1
                print(f"âœ… Processed student {student_id}")
        except Exception as e:
            print(f"âŒ Error processing student {student_id}: {e}")
    
    print(f"âœ… Processed {processed}/{len(student_ids)} students")
    return processed

def log_processing_results(**context):
    """Log les rÃ©sultats du traitement"""
    ti = context['ti']
    processed = ti.xcom_pull(task_ids='process_features')
    print(f"ðŸ“Š Processing completed: {processed} students processed")

# TÃ¢ches
sync_task = PythonOperator(
    task_id='sync_lms_data',
    python_callable=sync_lms_data,
    dag=dag,
)

process_task = PythonOperator(
    task_id='process_features',
    python_callable=process_student_features,
    dag=dag,
)

log_task = PythonOperator(
    task_id='log_results',
    python_callable=log_processing_results,
    dag=dag,
)

# DÃ©finir l'ordre d'exÃ©cution
sync_task >> process_task >> log_task

