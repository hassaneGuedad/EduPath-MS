# Guide de Questions/R√©ponses pour la Soutenance

Ce document regroupe les questions techniques probables que le jury pourrait vous poser, class√©es par th√©matique, avec des r√©ponses adapt√©es √† votre projet EduPath-MS.

---

## üèóÔ∏è 1. Architecture Microservices

**Q : Pourquoi avoir choisi une architecture microservices plut√¥t qu'un monolithe pour ce projet ?**
> **R :** Pour la **scalabilit√© ind√©pendante** et la **diversit√© technologique**. Le module de Machine Learning (Python/XGBoost) demande beaucoup de CPU, tandis que le Backend (Node.js/FastAPI) est plus l√©ger. Les microservices nous permettent de scaler uniquement la partie IA si n√©cessaire, et d'utiliser Python pour l'IA et Node.js pour les IO, ce qui serait impossible dans un monolithe unique.

**Q : Comment vos microservices communiquent-ils entre eux ?**
> **R :** Nous utilisons une approche hybride d√©taill√©e dans notre documentation :
> 1. **REST (Synchrone)** : Pour les appels directs du frontend et les requ√™tes simples (ex: r√©cup√©rer un profil utilisateur).
> 2. **RabbitMQ (Asynchrone)** : Pr√©vu pour les t√¢ches lourdes comme le calcul des pr√©dictions apr√®s un quiz, pour ne pas bloquer l'utilisateur.
> 3. **gRPC** : Envisag√© pour la communication rapide entre les services d'IA (ex: Profiler vers Predictor).

**Q : Comment g√©rez-vous la d√©couverte de services (Service Discovery) ?**
> **R :** Actuellement, nous utilisons le DNS interne de **Docker Compose** pour le d√©veloppement. Pour la production, nous avons planifi√© l'int√©gration d'**Eureka Server** et d'une **API Gateway** (Spring Cloud Gateway) pour centraliser le routage et la s√©curit√©.

---

## ü§ñ 2. Intelligence Artificielle & Data

**Q : Pourquoi avoir choisi XGBoost pour la pr√©diction d'√©chec ?**
> **R :** XGBoost est l'algorithme "√©tat de l'art" pour les donn√©es tabulaires (structur√©es comme nos notes et temps de connexion). Il est plus performant et plus rapide √† entra√Æner qu'un r√©seau de neurones profond (Deep Learning) sur ce type de donn√©es, et il offre une meilleure interpr√©tabilit√© (on peut savoir quelles features p√®sent le plus).

**Q : Comment g√©rez-vous le probl√®me de l'overfitting (surapprentissage) ?**
> **R :** C'est un point critique. Dans notre prototype actuel (MVP), nous utilisons des donn√©es synth√©tiques, donc le risque est pr√©sent. Pour la version finale, nous mettrons en place :
> 1. Une s√©paration stricte des donn√©es (80% Train, 20% Test).
> 2. Une **Cross-Validation** pour valider la robustesse du mod√®le.
> 3. L'arr√™t pr√©coce (Early Stopping) lors de l'entra√Ænement XGBoost.

**Q : Comment avez-vous d√©termin√© le nombre de profils (clusters) √† 3 pour le KMeans ?**
> **R :** C'est un choix m√©tier initial (High Performer, Average, At Risk) pour simplifier l'interface p√©dagogique. Techniquement, nous pourrions utiliser la m√©thode du coude (**Elbow Method**) pour v√©rifier si math√©matiquement 4 ou 5 groupes seraient plus pertinents.

---

## ‚öôÔ∏è 3. DevOps & Qualit√©

**Q : Quelle est votre strat√©gie de CI/CD ?**
> **R :** Nous utilisons **Jenkins**. Notre pipeline typique comprend :
> 1. **Checkout** du code.
> 2. **Build** des images Docker.
> 3. **Tests Unitaires** (Pytest pour Python).
> 4. **D√©ploiement** sur un environnement de staging via Docker Compose.

**Q : Pourquoi Docker ?**
> **R :** Docker garantit que "√ßa marche chez moi" marche aussi en production. Il isole les d√©pendances conflictuelles (ex: des versions diff√©rentes de Python pour diff√©rents services) et simplifie consid√©rablement le d√©ploiement de notre stack h√©t√©rog√®ne (Node, Python, Java).

---

## üõ°Ô∏è 4. S√©curit√©

**Q : Comment s√©curisez-vous les √©changes entre les services ?**
> **R :** Actuellement, nous nous reposons sur le r√©seau priv√© Docker. √Ä l'avenir, avec l'API Gateway, nous impl√©menterons l'authentification **JWT** centralis√©e : le Gateway valide le token avant de passer la requ√™te au microservice, d√©chargeant ainsi les services de cette logique.

**Q : Comment g√©rez-vous les donn√©es sensibles des √©tudiants (RGPD) ?**
> **R :** Les mots de passe sont hash√©s avec **Bcrypt**. Nous minimisons les donn√©es stock√©es. Une am√©lioration future serait d'anonymiser les donn√©es envoy√©es aux services de Machine Learning pour qu'ils travaillent sur des IDs et non des noms.

---

## üíæ 5. Base de Donn√©es & Data Persistence

**Q : Pourquoi avoir choisi PostgreSQL plut√¥t qu'une base NoSQL comme MongoDB ?**
> **R :** Nos donn√©es sont **relationnelles** et structur√©es par nature (√âtudiants, Cours, Devoirs, Notes). PostgreSQL garantit l'int√©grit√© r√©f√©rentielle (ACID), ce qui est crucial pour ne pas perdre de notes ou d'utilisateurs. Cependant, pour les logs d'activit√© ou les ressources non-structur√©es, une base NoSQL pourrait √™tre ajout√©e en compl√©ment √† l'avenir.

**Q : Comment g√©rez-vous les migrations de base de donn√©es ?**
> **R :** Dans le service Python (Auth), nous utilisons un script d'auto-migration au d√©marrage (voir `app.py`). En production, nous utiliserions un outil d√©di√© comme **Alembic** (pour Python) ou **Liquibase** pour versionner le sch√©ma de la base de donn√©es de mani√®re plus robuste.

---

## üíª 6. Frontend (React & Flutter)

**Q : Pourquoi avoir s√©par√© le Frontend (React) du Backend (API) ?**
> **R :** C'est le principe du **Decoupled Architecture**. Cela permet :
> 1. De changer le frontend sans toucher au backend (ex: refaire le design).
> 2. D'avoir plusieurs clients (Web React, Mobile Flutter, CLI) qui consomment la m√™me API.
> 3. De charger l'interface plus vite (SPA - Single Page Application) et de ne demander au serveur que les donn√©es JSON n√©cessaires.

**Q : Comment g√©rez-vous l'√©tat de l'application (State Management) c√¥t√© React ?**
> **R :** Nous utilisons les **Hooks** standards (`useState`, `useEffect`) pour les √©tats locaux. Si l'application grandit, nous passerions √† **Redux** ou **Context API** pour g√©rer l'√©tat global (ex: l'utilisateur connect√©) et √©viter le "prop drilling".

---

## üìà 7. Performance & Scalabilit√©

**Q : Que se passe-t-il si 10 000 √©tudiants se connectent en m√™me temps ?**
> **R :** 
> 1. **Load Balancing** : L'API Gateway r√©partirait la charge.
> 2. **Scaling Horizontal** : Avec Kubernetes, on lancerait automatiquement 10 ou 20 instances de nos microservices.
> 3. **Caching** : Nous devrions ajouter **Redis** pour mettre en cache les profils et les recommandations, √©vitant de recalculer ou de re-requ√™ter la base de donn√©es √† chaque clic.

**Q : Vos mod√®les ML sont-ils r√©-entra√Æn√©s en temps r√©el ?**
> **R :** Non, c'est trop co√ªteux. Le r√©-entra√Ænement se fait en **batch** (par exemple toutes les nuits) via un pipeline Airflow, sur les nouvelles donn√©es r√©colt√©es. Les pr√©dictions, elles, sont faites en temps quasi-r√©el (Inference) avec le mod√®le pr√©-entra√Æn√© charg√© en m√©moire.

---

## ü§ù 8. M√©thodologie & Travail d'√©quipe

**Q : Quelle m√©thodologie de gestion de projet avez-vous utilis√©e ?**
> **R :** Nous nous sommes inspir√©s de **Scrum**. Nous avons travaill√© par it√©rations (Sprints) : d'abord le MVP (Minimum Viable Product) avec l'auth et la base, puis l'ajout des services IA, et enfin l'interface graphique. Nous avons utilis√© Git pour versionner notre code et g√©rer les conflits.

**Q : Quelle a √©t√© la plus grande difficult√© technique ?**
> **R :** L'int√©gration des conteneurs Python (IA) avec les autres services. Python a besoin de nombreuses d√©pendances lourdes (pandas, numpy, scikit-learn), ce qui rendait les builds Docker lents et les images volumineuses. Nous avons optimis√© cela en utilisant des images de base slim et en g√©rant bien le cache Docker.

